---
title: Variogram modeling and kriging using gstat
author: Carles Milà
date: '2020-04-10'
slug: variogram-modeling-and-kriging-using-gstat
categories: []
tags:
  - Geostatistics
  - Spatial statistics
  - Parametric
  - Environment
  - R
description: ''
topics: []
---



<div id="geostatistics-basics" class="section level1">
<h1>Geostatistics basics</h1>
<p>Geostatistics concerns itself with processes that are continuous in space, such as precipitation or air pollution. Since the potential sampling points of a continuous surface are infinitely large, we will generally only sample at a limited amount of locations. The main focus of geostatistics will be to use the information found in these points to predict the whole surface of study. To do so, we rely on the semivariogram function, which models the persistence of the process in space.</p>
<p>These are the packages that will be used in this post</p>
<pre class="r"><code>library(&quot;tmap&quot;) # Cartography
library(&quot;plotKML&quot;) # Vector to raster 
library(&quot;cowplot&quot;) # Plot composition
library(&quot;gstat&quot;) # geostatistical modelling
library(&quot;raster&quot;) # raster classes
library(&quot;sf&quot;) # vector classes
library(&quot;tidyverse&quot;) # data management</code></pre>
<div id="geostatistical-processes-and-stationarity" class="section level2">
<h2>Geostatistical processes and stationarity</h2>
<p>Cressie’s (1993) general expression for spatial processes is:</p>
<p><span class="math display">\[Z(s): s \in D_s \]</span></p>
<p>We will say that <span class="math inline">\(Z(s)\)</span> is the value of the spatial process at location <span class="math inline">\(s\)</span>. In geostatistics, <span class="math inline">\(Z\)</span> will be a random and two-dimensional infinite continuous space <span class="math inline">\(D \subset \mathbb{R}^2\)</span>, also known as a random field. The goal of geostatistics will be to model the spatial correlation between observations and to use it for interpolation while verifying model hypothesis. Geostatistical processes are generally modelled as:</p>
<p><span class="math display">\[Z(s) = m(s) + \epsilon(s) \]</span></p>
<p>This is a sum of a mean component <span class="math inline">\(m(s)\)</span>, which represents the large-scale variation or spatial trend, and the innovations <span class="math inline">\(\epsilon(s)\)</span>, which are the small-scale variation.</p>
<p>While modelling the spatial trend is fairly easy by means of regression or another predictive method, some assumptions need to be taken as far as the errors are concerned. <span class="math inline">\(\epsilon(s)\)</span> will be a 0-mean random field from which we will have to estimate how observations are related to one another across space. In order to be able to do so, they have to be <strong>intrinsic stationary</strong>.</p>
<p>A geostatistical process will be <strong>strict stationary</strong> when the joint probability of the data is invariant to translations, i.e. it only depends on the relative positions of the sample sites. A weaker form is the <strong>second-order stationary</strong>, which assumes:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\text{E}[Z(s)]=\mu \quad \forall s \in D\)</span></li>
<li><span class="math inline">\(\text{Cov}(Z(s_1),Z(s_2))=\text{Cov}(s_1 - s_2)\)</span> for all <span class="math inline">\(s_1\)</span>, <span class="math inline">\(s_2 \in D\)</span></li>
</ol>
<p>That is, it assumes a constant mean and a covariance function that only depends on the relative locations. This also implies a constant variance, as <span class="math inline">\(\text{Cov}(Z(s),Z(s))=\text{Var}(Z(s))=\text{Cov}(s-s)=\text{Cov}(0) \quad \forall s \in D\)</span>.</p>
<p><strong>Intrinsic stationarity</strong> is even less restrictive. It requires:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\text{E}[Z(s)]=\mu \quad \forall s \in D\)</span></li>
<li><span class="math inline">\(\text{Var}(Z(s+h)-Z(s)) = \text{E}[(Z(s+h)-Z(s))^2] = 2 \gamma_Z(h)\)</span> for all <span class="math inline">\(s\)</span>, <span class="math inline">\(s+h \in D_s\)</span></li>
</ol>
<p>This implies a constant mean and a <strong>semivariogram</strong> function <span class="math inline">\(\gamma_Z(h)\)</span> that only depends on distance <span class="math inline">\(h\)</span> (<span class="math inline">\(2\gamma_Z(h)\)</span> is known as the variogram).</p>
<p>Assuming <strong>second order stationary</strong>, it can be shown that the variogram function:</p>
<p><span class="math display">\[\begin{align*}
\text{E}[(Z(s+h)-Z(s))^2] &amp; = \text{E}[Z(s+h)^2] + \text{E}[Z(s)^2] - 2 \text{E}[Z(s+h) \cdot Z(s)] \\
&amp; = \text{Cov}(Z(s+h),Z(s+h)) + \mu^2 + \text{Cov}(Z(s),Z(s)) + \mu^2 - 2 (\text{Cov}(Z(s+h),Z(s)) + \mu^2) \\
&amp; = \text{Cov}(Z(s+h),Z(s+h)) + \text{Cov}(Z(s),Z(s)) - 2 \text{Cov}(Z(s+h),Z(s)) \\
&amp; = 2\text{Cov}(0) - 2\text{Cov}(h)
\end{align*}\]</span></p>
<p>Is intrinsic stationary, as it depends on the process variance and a covariance that depends on the distance between locations. The converse is not always true. For estimating geostatistical models, we will assume the process to be <strong>intrinsic stationary</strong>.</p>
</div>
<div id="modelling-large-scale-variation" class="section level2">
<h2>Modelling large scale variation</h2>
<p>To fully characterise a geostatistical process, we have to model both <span class="math inline">\(m(s)\)</span> and <span class="math inline">\(\epsilon(s)\)</span>. First, we’ll model the trend, generally using regression analysis (<span class="math inline">\(Y = X \beta + \epsilon\)</span>). Some of the options for the trend are to assume an constant mean that can be either known or estimated (i.e. regression intercept) from the data. Another option is to use covariates, which will have to be continuously defined in all the area of study. These can be either the actual coordinates of the locations, or some external covariates.</p>
<p>As a first step of the analysis, a linear regression fit is done using OLS, and the residuals are taken to model their small-scale variation.</p>
</div>
<div id="modelling-small-scale-variation" class="section level2">
<h2>Modelling small scale variation</h2>
<p>In order to characterise the interaction between the errors, we’ll use the above defined <strong>semivariogram function</strong>. As a first step, we will estimate a sample semivariogram (method of moments) based on the following function:</p>
<p><span class="math display">\[\hat{\gamma}(h) = \frac{1}{2 N_h} \sum_{i=1}^{N_h} (Z(s_i) - Z(s_i + h))^2\]</span></p>
<p>where <span class="math inline">\(h\)</span> is spatial distance between observation and <span class="math inline">\(N_h\)</span> is the number of pairs that have that distance. In other words, for each distance <span class="math inline">\(h\)</span> defined in bins we will compute the sum of squared differences of pairs of observations that are <span class="math inline">\(h\)</span> spatial units apart, and divide it by two times the number of observations that have that distance. Bins do not have to be of equal range, nor must they cover all range of distances but rather concentrate on the small distances.</p>
<p>With the estimated sample semivariogram, we will choose a theoretical semivariogram function <span class="math inline">\(\hat\gamma(h;\theta)\)</span> and fit it to the data. This is done to ensure, among others, that prediction variances are not negative. This function will depend upon a set of parameters <span class="math inline">\(\theta\)</span> estimated from the sample semivariogram. Those are:</p>
<ol style="list-style-type: decimal">
<li>Nugget effect: Semivariance at distance h=0.</li>
<li>Range: Distance <span class="math inline">\(h\)</span> at which the semivariance tops.</li>
<li>Partial sill: Semivariance at the range minus nugget effect.</li>
</ol>
<p><img src="/post/2020-04-10-variogram-modeling-and-kriging-using-gstat_files/semivariogram.png" /></p>
<p>The most common theoretical functions for the semivariogram are the exponential, spherical and Matérn. Functions are chosen by visual inspection of the shape of the sample semivariogram:</p>
<pre class="r"><code>show.vgms(par.strip.text=list(cex=0.75))</code></pre>
<p><img src="/post/2020-04-10-variogram-modeling-and-kriging-using-gstat_files/figure-html/semivariograms-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>An additional assumption we are making is isotropy. Isotropy means that the semivariogram is the same in all directions. Anisotropy means that the semivariogram changes according to the angle. There are two kinds of anisotropy: geometrical anisotropy (different range) and zonal anisotropy (different sill). Geometrical anisotropy is fairly easy to solve by defying an ellipsoid instead of a circle for the semivariogram influence in the function, i.e. the effective range of the spatial correlation varies with the angle. Zonal anisotropy is more difficult to deal with. Anisotropy can be explored by computing sample semivariograms grouping by the direction of the spatial locations (in angles).</p>
<p>We fit the semivariogram function to the sample semivariogram using non-linear weighted least squares; therefore, sensible starting values for the parameters must be chosen to start the iterative process. There are different options for the weights, being <span class="math inline">\(N_h/h^2\)</span> a popular option as in gives more weight to short distances and distance bins have a larger number of observations.</p>
</div>
<div id="kriging-computations-and-types" class="section level2">
<h2>Kriging computations and types</h2>
<p>Kriging is an interpolation geostatistical method. It aims at predicting the value of the process at not sampled point locations (i.e. <span class="math inline">\(\hat{Z}(s_0)\)</span>) based on the observed data and an estimated semivariogram function. There are different types of kriging:</p>
<ol style="list-style-type: decimal">
<li>Simple kriging: Assumes no trend, <span class="math inline">\(m = \mu\)</span> is known and constant.</li>
<li>Ordinary kriging: Assumes no trend, <span class="math inline">\(m = \hat{\mu}\)</span> is unknown and constant.</li>
<li>Universal kriging: There is a trend and therefore <span class="math inline">\(m(s)\)</span> is not constant. Trend function estimated from the data coordinates using 1st or 2nd order polynomials (typically in a regression analysis).</li>
<li>Regression kriging: There is a trend and therefore <span class="math inline">\(m(s)\)</span> is not constant. Trend function estimated from covariates other than the coordinates.</li>
<li>Others: Stratified kriging, indicator kriging, block kriging, cokriging…</li>
</ol>
<p>Kriging is known to be the <strong>BLUP</strong> (best linear unbiased predictor). It is a linear combination of the data values <span class="math inline">\(\hat{Z}(s_0)=\sum_{i=1}^{n} \lambda_i Z(s_i)\)</span>, it is unbiased <span class="math inline">\(\text{E}[\hat{Z}(s_0)] = E[Z(s_0)]\)</span> and it minimises the prediction error variance <span class="math inline">\(\text{Var}(\hat{Z}(s_0) - Z(s_0))\)</span>. <span class="math inline">\(\lambda_i\)</span> are the kriging weights that we want to estimate to make predictions for a location <span class="math inline">\(s_0\)</span>.</p>
<p>Except for the simple kriging case (not likely to be encountered in real life), kriging involves minimising the prediction error variance subject to unbiasedness constraints. For ordinary kriging, it is as follows:</p>
<p><span class="math display">\[ \text{E}[Z(s_0)] - \text{E}[\hat{Z}(s_0)] = \text{E}[Z(s_0)] - \text{E}[\sum_{i=1}^{n} \lambda_i Z(s_i)] = 
m - \sum_{i=1}^{n} \lambda_i m = m(1-\sum_{i=1}^{n} \lambda_i) =0 \]</span></p>
<p>Where <span class="math inline">\(m\)</span> is the unknown mean in ordinary kriging. In other words, the ordinary kriging weights must add up to 1. Next, we find the weights by minimising the prediction error variance <span class="math inline">\(\text{Var}(\hat{Z}(s_0) - Z(s_0))\)</span> subject to this condition using Lagrange multipliers, i.e. we minimise the following expression by solving for <span class="math inline">\(\lambda_1, ..., \lambda_n, \phi\)</span>:</p>
<p><span class="math display">\[ \text{Var}(\hat{Z}(s_0) - Z(s_0)) - 2 \phi (\sum_{i=1}^{n} \lambda_i - 1) = E[(Z(s_0) - \sum_{i=1}^{n} \lambda_i Z(s_i))^2] - 2 \phi (\sum_{i=1}^{n} \lambda_i - 1) \]</span></p>
<p>Taking derivatives and solving the system yields expressions for both the kriging predictions and prediction variances. As we develop the algebra, we can plug in our semivariogram estimates taking into account that:</p>
<p><span class="math display">\[ \text{E}[(Z(s_i) - Z(s_j))^2] = \text{Var}(Z(s_i) - Z(s_j)) = 2 \gamma (s_i - s_j) \]</span></p>
<p>Universal Kriging is a generalization of ordinary kriging were more constraints are needed to be added into the system.</p>
</div>
</div>
<div id="data-analysis" class="section level1">
<h1>Data analysis</h1>
<div id="exploratory-analysis" class="section level2">
<h2>Exploratory analysis</h2>
<p>We read the data I have prepared for this example. It consists on data for 182 weather stations in the region of Catalunya, Spain with average temperature data (ºC) for 2018, a DEM for Catalunya, and the boundaries of the region.</p>
<pre class="r"><code>tempdata &lt;- read_sf(&quot;data/tempdata.geojson&quot;)
dem &lt;- raster(&quot;data/cat_dem.tif&quot;)
cat &lt;- read_sf(&quot;data/cat_boundary.geojson&quot;)</code></pre>
<p>We can do a nice representation of the data using <code>tmap</code>:</p>
<pre class="r"><code>tm1 &lt;- tm_shape(cat) +
    tm_borders() +
tm_shape(tempdata) +
    tm_dots(col = &quot;temp&quot;, size = 0.4, palette = &quot;-Spectral&quot;, n = 5) 
tm2 &lt;- tm_shape(cat) +
    tm_borders() +
tm_shape(dem) +
    tm_raster(&quot;cat_dem&quot;, palette = terrain.colors(10), style = &quot;cont&quot;)
tmap_arrange(tm1, tm2, nrow = 1)</code></pre>
<p><img src="/post/2020-04-10-variogram-modeling-and-kriging-using-gstat_files/figure-html/plotdata-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>To gain a first glimpse of how the interpolated data may look like, we do an IDW exploratory interpolation (1km grid).</p>
<pre class="r"><code># We make 10km prediction grid, add coordinates and elevation
gridcat &lt;- st_make_grid(cat, cellsize = 1000, what = &quot;centers&quot;) %&gt;%
  st_sf() %&gt;%
  mutate(x = st_coordinates(.)[,1],
         y = st_coordinates(.)[,2],
         elev = raster::extract(dem, .))
# Compute IDW and convert to raster
idwtemp &lt;- idw(temp ~ 1, tempdata, gridcat) %&gt;% # p default = 2
  rename(temp = var1.pred) %&gt;%
  select(temp) 
idwtemp  &lt;- vect2rast(as(idwtemp, &quot;Spatial&quot;), cell.size = 1000)</code></pre>
<pre class="r"><code># And plot
tm_shape(idwtemp) +
  tm_raster(&quot;temp&quot;, palette = &quot;-Spectral&quot;, style = &quot;cont&quot;) +
tm_layout(legend.position = c(&quot;right&quot;, &quot;bottom&quot;))</code></pre>
<p><img src="/post/2020-04-10-variogram-modeling-and-kriging-using-gstat_files/figure-html/idw%20map-1.png" width="288" style="display: block; margin: auto;" /></p>
<p>Only by looking at the IDW map we can already see a large-scale trend in our data, which makes the assumption of intrinsic stationary process not hold, as the mean is clearly not constant. Therefore, interpolation methods such as Ordinary kriging (OK) are not appropriate. For the sake of this exercise, we will do it nonetheless. Before starting our variogram modelling, let us check how correlated is mean temperature with the three covariates we are going to use: x, y, and elevation.</p>
<pre class="r"><code># Extract elevation of the stations
tempdata$elev &lt;- raster::extract(dem, tempdata)
# Plots with linear fit
theme_set(theme_bw())
p1 &lt;- ggplot(tempdata, aes(y = temp, x = x)) +
  geom_point() +
  geom_smooth(method = &quot;lm&quot;)
p2 &lt;- ggplot(tempdata, aes(y = temp, x = y)) +
  geom_point() +
  geom_smooth(method = &quot;lm&quot;)
p3 &lt;- ggplot(tempdata, aes(y = temp, x = elev)) +
  geom_point() +
  geom_smooth(method = &quot;lm&quot;)
plot_grid(p1, p2, p3, nrow=1)</code></pre>
<p><img src="/post/2020-04-10-variogram-modeling-and-kriging-using-gstat_files/figure-html/correlation-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>While the correlation of the temperatures with the coordinates is limited, there is a very strong correlation between temperature and elevation. One first approach to evaluate the spatial autocorrelation of the data is the lagged scatterplot, where scatterplots of each pair of observations are generated and binned by distance between each pair.</p>
<pre class="r"><code>hscat(temp~1, tempdata, breaks = seq(0, 120000, by = 20000))</code></pre>
<p><img src="/post/2020-04-10-variogram-modeling-and-kriging-using-gstat_files/figure-html/lagged_scatter-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>There are signs of strong spatial autocorrelation in the data: while correlations for small distances are large, those tend to 0 when the distance between observations increases.</p>
</div>
<div id="variogram-modelling" class="section level2">
<h2>Variogram modelling</h2>
<p>We will start by plotting variogram clouds and sample variograms for OK, UK and RK models. We use bins of 10km until a maximum distance of 250km to calculate the sample variogram.</p>
<pre class="r"><code># OK
p1 &lt;- plot(variogram(temp~1, data=tempdata, cloud=TRUE, cutoff=250000), main=&quot;OK: Variogram cloud&quot;)
varOK &lt;- variogram(temp~1, data=tempdata, cutoff=250000, width = 10000)
p2 &lt;- plot(varOK, main=&quot;OK: Sample variogram&quot;)
# UK
p3 &lt;- plot(variogram(temp~x+y, data=tempdata, cloud=TRUE, cutoff=250000), main=&quot;UK: Variogram cloud&quot;)
varUK &lt;- variogram(temp~x+y, data=tempdata, cutoff=250000, width = 10000)
p4 &lt;- plot(varUK, main=&quot;UK: Sample variogram&quot;)
# RK
p5 &lt;- plot(variogram(temp~elev, data=tempdata, cloud=TRUE, cutoff=250000), main=&quot;RK: Variogram cloud&quot;)
varRK &lt;- variogram(temp~elev, data=tempdata, cutoff=250000, width = 10000)
p6 &lt;- plot(varRK, main=&quot;RK: Sample variogram&quot;)
# Plot
plot_grid(p1, p3, p5, p2, p4, p6, nrow = 2)</code></pre>
<p><img src="/post/2020-04-10-variogram-modeling-and-kriging-using-gstat_files/figure-html/varcloudsample-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>If we have a look at the y-axis, we’ll see that OK is the one with higher semivariances, followed by UK and RK. This is due to the fact that covariates in UK and RK have managed to explain part of the data variability. Now it’s time to fit the theoretical variograms. We will use gaussian variograms for OK and RK and spherical for UK. Starting values are set according to visual inspection of the sample variograms.</p>
<pre class="r"><code># OK
varOK.fit &lt;- fit.variogram(varOK, vgm(psill = 22, model=&quot;Gau&quot;, range = 200000, nugget = 3))
p1 &lt;- plot(varOK, varOK.fit, main = &quot;OK&quot;)
# UK
varUK.fit &lt;- fit.variogram(varUK, vgm(psill = 5, model=&quot;Gau&quot;, range = 100000, nugget = 2))
p2 &lt;- plot(varUK, varUK.fit, main = &quot;UK&quot;)
# RK
varRK.fit &lt;- fit.variogram(varRK, vgm(psill = 0.6, model=&quot;Exp&quot;, range = 200000, nugget = 0.2))
p3 &lt;- plot(varRK, varRK.fit, main = &quot;RK&quot;)
# Plot
plot_grid(p1, p2, p3, nrow = 1)</code></pre>
<p><img src="/post/2020-04-10-variogram-modeling-and-kriging-using-gstat_files/figure-html/fit%20variograms-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>As a last check, we assess whether the isotropy assumption is reasonable for our data. To do so, we plot directional sample variograms and observe whether they have different ranges (geometric anisotropy). Note than gstat cannot handle zonal anisotropy directly (different sills), however, it can be “tricked” using geometric anisotropy parameters. This is illustrated in our data: while directional variograms for UK and RK look fine, for OK:</p>
<pre class="r"><code>varOK.ani &lt;- variogram(temp~1, alpha=c(0, 45, 90, 135), data=tempdata, cutoff=250000)
plot(varOK.ani, varOK.fit)</code></pre>
<p><img src="/post/2020-04-10-variogram-modeling-and-kriging-using-gstat_files/figure-html/unnamed-chunk-1-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>We see that autocorrelation happens mostly in the 0 (North) and 135 (Southeast) direction, so we have zonal anisotropy. We can fix it by playing with the geometric anisotropy parameters, by setting very large ranges for directions with less autocorrelation. Unfortunately, <code>gstat</code> does not have capabilities to fit anisotropy parameters so we have to do the fit by visual inspection:</p>
<pre class="r"><code>varOK.ani &lt;- variogram(temp~1, alpha=c(0, 45, 90, 135), data=tempdata, cutoff = 250000)
varOK.fitani &lt;- vgm(psill = 75, model=&quot;Gau&quot;, 
                    range = 1500000, nugget = 2,
                    anis = c(70, 0.1))
plot(varOK.ani, varOK.fitani)</code></pre>
<p><img src="/post/2020-04-10-variogram-modeling-and-kriging-using-gstat_files/figure-html/varani-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>This is much better. Note that this shape is caused by the presence of a large-scale trend in the data that makes OK unsuitable.</p>
</div>
<div id="kriging" class="section level2">
<h2>Kriging</h2>
<p>Time to krige! We will predict all locations in the Catalunya grid (1km) using the fitted variogram for each of the kriging modes.</p>
<pre class="r"><code># OK
krigOK &lt;- krige(temp ~ 1, tempdata, gridcat, model = varOK.fitani)
krigOK.preds &lt;- vect2rast(as(krigOK, &quot;Spatial&quot;), fname = &quot;var1.pred&quot;, cell.size = 1000)
names(krigOK.preds) &lt;- &quot;Temp_predictions&quot;
krigOK.vars &lt;- vect2rast(as(krigOK, &quot;Spatial&quot;), fname = &quot;var1.var&quot;, cell.size = 1000)
names(krigOK.vars) &lt;- &quot;Temp_variance&quot;
# UK
krigUK &lt;- krige(temp ~ x+y, tempdata, gridcat, model = varUK.fit)
krigUK.preds &lt;- vect2rast(as(krigUK, &quot;Spatial&quot;), fname = &quot;var1.pred&quot;, cell.size = 1000)
names(krigUK.preds) &lt;- &quot;Temp_predictions&quot;
krigUK.vars &lt;- vect2rast(as(krigUK, &quot;Spatial&quot;), fname = &quot;var1.var&quot;, cell.size = 1000)
names(krigUK.vars) &lt;- &quot;Temp_variance&quot;
# RK
krigRK &lt;- krige(temp ~ elev, tempdata, gridcat, model = varRK.fit)
krigRK.preds &lt;- vect2rast(as(krigRK, &quot;Spatial&quot;), fname = &quot;var1.pred&quot;, cell.size = 1000)
names(krigRK.preds) &lt;- &quot;Temp_predictions&quot;
krigRK.vars &lt;- vect2rast(as(krigRK, &quot;Spatial&quot;), fname = &quot;var1.var&quot;, cell.size = 1000)
names(krigRK.vars) &lt;- &quot;Temp_variance&quot;</code></pre>
<p>We do a cartographic representation of predictions in the same scale to allow comparison of the predictions. Variances are not in the same scale as those for RK are much lower than the rest.</p>
<pre class="r"><code>p1 &lt;- tm_shape(krigOK.preds) +
    tm_raster(&quot;Temp_predictions&quot;, palette = &quot;-Spectral&quot;, style = &quot;cont&quot;, breaks = c(0, 20)) +
    tm_layout(title = &quot;OK&quot;, legend.position = c(&quot;right&quot;, &quot;bottom&quot;))
p2 &lt;- tm_shape(krigOK.vars) +
    tm_raster(&quot;Temp_variance&quot;, style = &quot;cont&quot;, palette = &quot;Blues&quot;) +
    tm_layout(title = &quot;OK&quot;, legend.position = c(&quot;right&quot;, &quot;bottom&quot;))
p3 &lt;- tm_shape(krigUK.preds) +
    tm_raster(&quot;Temp_predictions&quot;, palette = &quot;-Spectral&quot;, style = &quot;cont&quot;, breaks = c(0, 20)) +
    tm_layout(title = &quot;UK&quot;, legend.position = c(&quot;right&quot;, &quot;bottom&quot;))
p4 &lt;- tm_shape(krigUK.vars) +
    tm_raster(&quot;Temp_variance&quot;, style = &quot;cont&quot;, palette = &quot;Blues&quot;) +
    tm_layout(title = &quot;UK&quot;, legend.position = c(&quot;right&quot;, &quot;bottom&quot;))
p5 &lt;- tm_shape(krigRK.preds) +
    tm_raster(&quot;Temp_predictions&quot;, palette = &quot;-Spectral&quot;, style = &quot;cont&quot;, breaks = c(0, 20), midpoint = NA) +
    tm_layout(title = &quot;RK&quot;, legend.position = c(&quot;right&quot;, &quot;bottom&quot;))
p6 &lt;- tm_shape(krigRK.vars) +
    tm_raster(&quot;Temp_variance&quot;, style = &quot;cont&quot;, palette = &quot;Blues&quot;) +
    tm_layout(title = &quot;RK&quot;, legend.position = c(&quot;right&quot;, &quot;bottom&quot;))
tmap_arrange(p1, p3, p5, p2, p4, p6, nrow = 2)</code></pre>
<p><img src="/post/2020-04-10-variogram-modeling-and-kriging-using-gstat_files/figure-html/cartokriging-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="validation" class="section level2">
<h2>Validation</h2>
<p>Since kriging is a prediction method, it makes sense to assess its performance using cross-validation, namely leave-one-out CV: we predict the value for each of the data points using the rest of the sample and the estimated semivariogram.</p>
<pre class="r"><code>krigOK.cv &lt;- krige.cv(temp ~ 1, tempdata, varOK.fitani)
krigUK.cv &lt;- krige.cv(temp ~ x+y, tempdata, varUK.fit)
krigRK.cv &lt;- krige.cv(temp ~ elev, tempdata, varRK.fit)</code></pre>
<p>Then we need a goodness of fit statistic to evaluate the results. One usual choice is the <em>Root Mean Square Error</em> (RMSE):</p>
<p><span class="math display">\[ RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^n (\hat{y}_i - y_i)^2} \]</span></p>
<pre class="r"><code>krigOK.mse &lt;- round(sqrt(mean(krigOK.cv$residual^2)), 2)
krigUK.mse &lt;- round(sqrt(mean(krigUK.cv$residual^2)), 2)
krigRK.mse &lt;- round(sqrt(mean(krigRK.cv $residual^2)), 2)</code></pre>
<p>The RMSE of OK is 2.15, the RMSE for UK is 1.81 and the RMSE for RK is 0.53. For this example, RK is clearly superior as the DEM is strongly correlated with temperature.</p>
</div>
</div>
<div id="bibliography" class="section level1">
<h1>Bibliography</h1>
<ul>
<li>Bivand, Roger S., et al. Applied spatial data analysis with R. Vol. 747248717. New York: Springer, 2008.</li>
<li>Gelfand, Alan E., et al. Handbook of spatial statistics. CRC press, 2010.</li>
<li>Pebesma, Edzer J. “Gstat user’s manual.” Dept. of Physical Geography, Utrecht University, Utrecht, The Netherlands (2001).</li>
</ul>
</div>
